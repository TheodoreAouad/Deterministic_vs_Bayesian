{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_tuto.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxXSsaJooLtX",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmy6VJEGmgfj",
        "colab_type": "code",
        "outputId": "ec604b5c-9858-4d3d-bfbd-a38eda142c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# %% Imports\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "device = torch.device(device)\n",
        "print(device)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "turssu_AoHo0",
        "colab_type": "text"
      },
      "source": [
        "## Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_4-ekhCndsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %% Datasets\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data',train=True, transform=transform ,download=True)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data',train=False, transform=transform ,download=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzwIgFiJoRfK",
        "colab_type": "code",
        "outputId": "f546d62f-fccc-4066-fa6f-ac6da480d656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# %% Plot image\n",
        "\n",
        "iter_train = iter(trainloader)\n",
        "image, label = next(iter_train)\n",
        "plt.imshow(image[0,0,:,:])\n",
        "print(label)\n",
        "plt.show()\n",
        "image =image.to(device)\n",
        "label = label.to(device)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([7, 9, 3, 6, 0, 7, 9, 1, 4, 7, 8, 3, 6, 9, 3, 8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYxaPbZaQROb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %% Def training\n",
        "\n",
        "\n",
        "def train(model, optimizer, criterion, number_of_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    for epoch in range(number_of_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        number_of_data = len(trainloader)\n",
        "        interval = number_of_data // 10\n",
        "        running_loss = 0.0\n",
        "        number_of_correct_labels = 0\n",
        "        number_of_labels = 0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            # get the inputs; data is a list of [inputs, labels]\n",
        "            inputs, labels = [x.to(device) for x in data]\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            predicted_labels = outputs.argmax(1)\n",
        "            number_of_correct_labels += torch.sum(predicted_labels - labels == 0).item()\n",
        "            number_of_labels += labels.size(0)\n",
        "            if i % interval == interval-1:  \n",
        "                print(f'Train: [{epoch + 1}, {i + 1}/{number_of_data}] loss: {running_loss / number_of_data}, '\n",
        "                      f'Acc: {round(100*number_of_correct_labels/number_of_labels,2)} %')\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "# %%\n",
        "\n",
        "def test(model):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    number_of_correct_labels = 0\n",
        "    number_of_labels = 0\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "\n",
        "        inputs, labels = [x.to(device) for x in data]\n",
        "        outputs = model(inputs)\n",
        "        predicted_labels = outputs.argmax(1)\n",
        "        number_of_correct_labels += torch.sum(predicted_labels - labels == 0).item()\n",
        "        number_of_labels += labels.size(0)\n",
        "        if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "            print(f' Test: {i + 1} loss: {running_loss / 2000}, '\n",
        "                  f'Acc: {round(100*number_of_correct_labels / number_of_labels, 2)} %')\n",
        "            running_loss = 0.0\n",
        "    print(f'Test accuracy: {round(100*number_of_correct_labels / number_of_labels, 2)} %')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLH0HdY1oam8",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdUaBkR6mm4i",
        "colab_type": "text"
      },
      "source": [
        "# %% Define modules\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yIry0bCaBaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_weights(channel_out,channel_input,width,height):\n",
        "    k = 1./ (channel_input * width * height)\n",
        "    return (torch.rand(channel_out,channel_input,width,height)-0.5) * torch.sqrt(torch.Tensor([k]))\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98dLH2m0Fpg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeterministClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, number_of_classes):\n",
        "        super(DeterministClassifier,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,16,3,padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        self.fc1 = nn.Linear(32*7*7, number_of_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1,32*7*7)\n",
        "        output = F.softmax(self.fc1(x))\n",
        "\n",
        "        return output\n",
        "\n",
        "class ProbabilistClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, number_of_classes):\n",
        "        super(ProbabilistClassifier,self).__init__()\n",
        "        \n",
        "        self.mu1 = nn.Parameter(data=init_weights(16,1,3,3),requires_grad=True)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "        self.mu2 = nn.Parameter(data=init_weights(32,16,3,3),requires_grad=True)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        \n",
        "        #self.mufc = nn.Parameter(data=torch.rand(10,16*14*14),requires_grad=True)\n",
        "        self.fc1 = nn.Linear(32*7*7, number_of_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = \n",
        "        x = self.pool1(F.relu(F.conv2d(x,self.mu1 + self.sigma*random(),padding=1)))\n",
        "        x = self.pool2(F.relu(F.conv2d(x,self.mu2,padding=1)))\n",
        "        x = x.view(-1,32*7*7)\n",
        "        output = F.softmax(self.fc1(x))\n",
        "        #output = F.softmax(F.linear(x, self.mufc))\n",
        "        return output\n",
        "    \n",
        "class ProbabilistClassifier2(nn.Module):\n",
        "    \n",
        "    def __init__(self, number_of_classes):\n",
        "        super(ProbabilistClassifier2,self).__init__()\n",
        "        self.mu1 = nn.Parameter(data=torch.rand(16,1,3,3),requires_grad=True)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "        self.mu2 = nn.Parameter(data=torch.rand(32,16,3,3),requires_grad=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        self.mufc = nn.Parameter(data=torch.rand(10,32*7*7),requires_grad=True)\n",
        "       # self.fc1 = nn.Linear(32*7*7, number_of_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = nn.Conv2d(1,16,3,padding=1).to(device)\n",
        "        conv1.weight.data = self.mu1\n",
        "        conv2 = nn.Conv2d(16,32,3,padding=1).to(device)\n",
        "        conv2.weight.data = self.mu2\n",
        "        \n",
        "        x = self.pool1(F.relu(conv1(x)))\n",
        "        x = self.pool2(F.relu(conv2(x)))\n",
        "        x = x.view(-1,32*7*7)\n",
        "        #output = F.softmax(self.fc1(x))\n",
        "        output = F.softmax(F.linear(x, self.mufc))\n",
        "        return output\n",
        "    \n",
        "class DenseProbabilistClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, number_of_classes):\n",
        "        super(DenseProbabilistClassifier,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,16,3,padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(16,32,3,padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "\n",
        "        #self.fc1 = nn.Linear(32*7*7, number_of_classes)\n",
        "        self.mu1 = nn.Parameter(data=torch.rand(10,32*7*7),requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1,32*7*7)\n",
        "        #output = F.softmax(self.fc1(x))\n",
        "        weights = self.mu1\n",
        "        output = F.softmax(F.linear(x,weights))\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5mnqRhtUW_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_proba = ProbabilistClassifier(10)\n",
        "model_proba.to(device)\n",
        "adam_proba = optim.Adam(model_proba.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hie0bl8kYQTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_proba.mu1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKiM1y2oqA8N",
        "colab_type": "code",
        "outputId": "4476f28b-1970-425c-d0b9-b225a4d718b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "train(model_proba,adam_proba,criterion,1)\n"
      ],
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: [1, 375/3750] loss: 0.175157230981191, Acc: 72.15 %\n",
            "<NllLossBackward object at 0x7f2550c65cf8>\n",
            "Train: [1, 750/3750] loss: 0.16267022879918416, Acc: 77.97 %\n",
            "<NllLossBackward object at 0x7f2550c651d0>\n",
            "Train: [1, 1125/3750] loss: 0.15572323481241862, Acc: 82.24 %\n",
            "<NllLossBackward object at 0x7f2550c658d0>\n",
            "Train: [1, 1500/3750] loss: 0.15196398865381877, Acc: 85.29 %\n",
            "<NllLossBackward object at 0x7f2550c65748>\n",
            "Train: [1, 1875/3750] loss: 0.15152535219192506, Acc: 87.2 %\n",
            "<NllLossBackward object at 0x7f2550c65748>\n",
            "Train: [1, 2250/3750] loss: 0.1513173193613688, Acc: 88.51 %\n",
            "<NllLossBackward object at 0x7f2550c657b8>\n",
            "Train: [1, 2625/3750] loss: 0.15105015672047933, Acc: 89.47 %\n",
            "<NllLossBackward object at 0x7f2550c657b8>\n",
            "Train: [1, 3000/3750] loss: 0.1503132563908895, Acc: 90.27 %\n",
            "<NllLossBackward object at 0x7f2550c65828>\n",
            "Train: [1, 3375/3750] loss: 0.149904935614268, Acc: 90.95 %\n",
            "<NllLossBackward object at 0x7f2550c651d0>\n",
            "Train: [1, 3750/3750] loss: 0.1500174873352051, Acc: 91.47 %\n",
            "<NllLossBackward object at 0x7f2550c65828>\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds5zqudHQc0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b42b75ff-060f-4f30-9ec4-c17960bef9fa"
      },
      "source": [
        "model_proba.zero_grad()\n",
        "output = model_proba(image)\n",
        "loss = criterion(output,label)\n",
        "loss.backward()\n",
        "[(name, torch.abs(k.grad).sum()) if k.grad is not None else (name,k.grad) for (name, k) in model_proba.named_parameters()]"
      ],
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mu1', tensor(0.5091, device='cuda:0')),\n",
              " ('mu2', tensor(2.7432, device='cuda:0')),\n",
              " ('fc1.weight', tensor(180.2423, device='cuda:0')),\n",
              " ('fc1.bias', tensor(0.0334, device='cuda:0'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 294
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppvHuLmOXwVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1343
        },
        "outputId": "7fd4c3f3-bdec-4461-819b-07db3ceb0f0f"
      },
      "source": [
        "model = DeterministClassifier(10)\n",
        "model.conv1.weight.data"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.3315,  0.3295, -0.0089],\n",
              "          [ 0.1450, -0.3100, -0.1409],\n",
              "          [ 0.0284, -0.3216,  0.0384]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0680,  0.1758,  0.2656],\n",
              "          [ 0.0437,  0.0955, -0.1784],\n",
              "          [-0.2123, -0.3266,  0.0280]]],\n",
              "\n",
              "\n",
              "        [[[-0.2569, -0.2571, -0.2754],\n",
              "          [-0.2883, -0.0703,  0.1990],\n",
              "          [ 0.2720,  0.0206,  0.0062]]],\n",
              "\n",
              "\n",
              "        [[[-0.1546, -0.2378,  0.1914],\n",
              "          [ 0.2666,  0.3301, -0.0437],\n",
              "          [ 0.2658,  0.3119, -0.1413]]],\n",
              "\n",
              "\n",
              "        [[[-0.0411, -0.2840,  0.2892],\n",
              "          [ 0.1991,  0.1910,  0.1826],\n",
              "          [ 0.1032,  0.3029,  0.0534]]],\n",
              "\n",
              "\n",
              "        [[[-0.0357,  0.0159,  0.0182],\n",
              "          [ 0.2724, -0.0514, -0.1378],\n",
              "          [-0.2161,  0.0393, -0.0480]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0095,  0.1137,  0.2032],\n",
              "          [ 0.1709, -0.2291,  0.0639],\n",
              "          [-0.3150,  0.0808,  0.2071]]],\n",
              "\n",
              "\n",
              "        [[[-0.2287,  0.2490, -0.0311],\n",
              "          [ 0.1692, -0.0311,  0.2424],\n",
              "          [-0.0575, -0.2360, -0.1771]]],\n",
              "\n",
              "\n",
              "        [[[-0.1679, -0.0989,  0.0123],\n",
              "          [ 0.0902,  0.3133, -0.1787],\n",
              "          [ 0.1880,  0.0241, -0.0526]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0033,  0.0924,  0.1317],\n",
              "          [ 0.0687, -0.2991, -0.1658],\n",
              "          [-0.2477, -0.2724, -0.0099]]],\n",
              "\n",
              "\n",
              "        [[[-0.1937, -0.1853,  0.1279],\n",
              "          [-0.2890, -0.0374, -0.2912],\n",
              "          [-0.1863, -0.0893, -0.2236]]],\n",
              "\n",
              "\n",
              "        [[[-0.1076, -0.2833, -0.1050],\n",
              "          [-0.2959, -0.0076,  0.2848],\n",
              "          [-0.2954, -0.2089,  0.0691]]],\n",
              "\n",
              "\n",
              "        [[[ 0.2948, -0.0183,  0.2301],\n",
              "          [-0.1629, -0.3240, -0.2968],\n",
              "          [ 0.1565,  0.1250, -0.2495]]],\n",
              "\n",
              "\n",
              "        [[[-0.0045, -0.1142,  0.0236],\n",
              "          [ 0.0363,  0.2186, -0.2336],\n",
              "          [-0.1688, -0.1556, -0.2910]]],\n",
              "\n",
              "\n",
              "        [[[-0.2290,  0.3281,  0.2843],\n",
              "          [ 0.0756,  0.1247, -0.1027],\n",
              "          [ 0.1718, -0.0423,  0.2362]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0990,  0.2683, -0.1021],\n",
              "          [-0.3055, -0.2064,  0.0261],\n",
              "          [-0.2843,  0.0844, -0.2030]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upF8WIrmQ-Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "970f9b09-c5bc-46e2-c855-48084d4c4bab"
      },
      "source": [
        "[(name, torch.abs(k.grad).sum()) if k.grad is not None else (name,k.grad) for (name, k) in model_proba.named_parameters()]"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mu1', tensor(0., device='cuda:0')),\n",
              " ('mu2', tensor(0., device='cuda:0')),\n",
              " ('fc1.weight', tensor(0., device='cuda:0')),\n",
              " ('fc1.bias', tensor(0., device='cuda:0'))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJimGXOIB5y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[(name, k.grad) if k is not None else (name,k) for (name, k) in model_dense_proba.named_parameters()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujUCWICBBfJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dense_proba = DenseProbabilistClassifier(nn.Module)\n",
        "model_dense_proba.to(device)\n",
        "adam_proba_dense = optim.Adam(model_dense_proba.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMKNF5jzBuY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model_dense_proba,adam_proba_dense,criterion,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwkctLJXs0pw",
        "colab_type": "code",
        "outputId": "3f10055b-a53b-477f-db7e-1e74427fa03e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[torch.abs(k.grad).sum() for k in list(model.fc1.parameters())]"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(7.8311, device='cuda:0'), tensor(0.0102, device='cuda:0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBr3mXloHF2a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %% Definition of model\n",
        "\n",
        "model = DeterministClassifier(number_of_classes=10)\n",
        "model.to(device)\n",
        "sgd = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "adam = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8a1psQ2HGpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %% Training\n",
        "number_of_epochs = 3\n",
        "train(model, adam, criterion, number_of_epochs)\n",
        "\n",
        "# %% Testing\n",
        "test(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}